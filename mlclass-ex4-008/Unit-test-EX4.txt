Test 1a (Feedforward and Cost Function):
input_layer_size = 2;
hidden_layer_size = 3;
num_labels = 4;
m3 = magic(3); m4 = magic(4);
nn_params = [m3(:) ; m4(:) ];
X = [cos([1, 2]) ; sin([3, 4])];
y = [4; 2];
lambda = 0;
nnCostFunction(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lambda)
output:
ans = 90.877




Test 2a (Regularized Cost Function):

input_layer_size = 2;
hidden_layer_size = 3;
num_labels = 4;
m3 = magic(3); m4 = magic(4);
nn_params = [m3(:) ; m4(:) ];
X = [cos([1, 2]) ; sin([3, 4])];
y = [4; 2];
lambda = 3;
nnCostFunction(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lambda)

output:
ans = 1076.4

Test 3a (Sigmoid Gradient):
input:
sigmoidGradient(1)

output:
ans =  0.19661

Test 3b:
input:
sigmoidGradient([2 3])

output:
ans =

   0.104994   0.045177

-------
Test 3c:
input:
sigmoidGradient([-2 0; 4 999999; -1 1])

output:
ans =

   0.10499   0.25000
   0.01766   0.00000
   0.19661   0.19661


Test 4a (Neural Network Gradient (Backpropagation)):
input:
input_layer_size = 2;
hidden_layer_size = 3;
num_labels = 4;
m3 = magic(3); m4 = magic(4);
nn_params = [m3(:) ; m4(:) ];
% CTA note: the above syntax may not work for Matlab users. Split the statement into separate lines.
X = [cos([1, 2]) ; sin([3, 4])];
y = [4; 2];
lambda = 0;
[J grad] = nnCostFunction(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lambda)
output:
J =  90.877
grad =

   0.321266
   2.204684
   0.295411
   0.054767
   0.518149
   0.043830
  -0.235088
  -1.491839
  -0.221740
   1.000000
   0.500000
   1.000000
   0.500000
   0.985522
   0.498816
   0.985522
   0.486705
   0.555575
   0.471025
   0.555575
   0.084550
   0.988421
   0.499837
   0.988421
   0.488584





Test 5a (Regularized Gradient):
input_layer_size = 2;
hidden_layer_size = 3;
num_labels = 4;
m3 = magic(3); m4 = magic(4);
nn_params = [m3(:) ; m4(:) ];
X = [cos([1, 2]) ; sin([3, 4])];
y = [4; 2];
lambda = 3;
[J grad] = nnCostFunction(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, lambda)
output:
J =  1076.4
grad =

    0.32127
    2.20468
    0.29541
    1.55477
    8.01815
   13.54383
    8.76491
    9.00816
    2.77826
    1.00000
    0.50000
    1.00000
    0.50000
    3.98552
   16.99882
   11.48552
   21.48671
    5.05558
   15.47103
    9.55558
   22.58455
   20.48842
   12.49984
   18.98842
    1.98858
